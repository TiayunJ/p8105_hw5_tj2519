---
title: "p8105_hw5_tj2519"
output: github_document
date: "2023-11-08"
---

# Problem 0: load library and some initial setup
```{r}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

# Problem 1
## create the new variable
```{r}
pro1_df = 
  read_csv("data_p1/homicide-data.csv") %>% 
  mutate(city_state = paste(city, state, sep = ", ")) %>% 
  mutate(city_state = str_replace(city_state,"Tulsa, AL", "Tulsa, OK"))

```

## summarize dataset & Baltimore
```{r}
clean_df = pro1_df %>% 
  mutate(disposition = 
           ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), "Unsolved homicides", "Solved homicides")) %>%
  group_by(city_state, disposition) %>% 
  summarize(obs = n()) %>% 
  pivot_wider(names_from = "disposition", values_from = "obs") %>% 
  janitor::clean_names() %>% 
  mutate(total = sum(solved_homicides, unsolved_homicides))

bal = clean_df %>% 
  filter(city_state == "Baltimore, MD")
  
results = 
  prop.test(pull(bal, solved_homicides), pull(bal, total), conf.level = 0.95) %>% 
  broom::tidy() %>% 
  janitor::clean_names() %>% 
  select(estimate, conf_low, conf_high)
  
```


##for each city, calculate the prop
```{r}
prop = function(df) {
  
  results = 
  prop.test(pull(df, solved_homicides), pull(df, total), conf.level = 0.95) %>% 
  broom::tidy() %>% 
  janitor::clean_names() %>% 
  select(estimate, conf_low, conf_high)
  
  results
}


clean_df_nest =
  nest(clean_df, data = solved_homicides:total) %>% 
  mutate(results = map(data, prop)) %>% 
  unnest(data) %>% 
  unnest(results) %>% 
  select(-solved_homicides)


```

## plot
```{r}
clean_df_nest %>% 
  mutate(city_state = forcats::fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate, fill = city_state)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high))
```





# Problem 2
## readin the names of all csv files, store the names in a dataframe
```{r}
pro2_df = 
  tibble(file = list.files(path = "data")) 

```

## Write a function to read the data in each csv filecreate another dataframe to store the data in each csv file, and put the data into the existed dataframe
```{r message = FALSE}
read_data = function(df) {
  df_path = paste("data", as.character(df), sep = "/")
 
  read_csv(df_path) %>% 
  janitor::clean_names()

}

data_only = 
  map(pull(pro2_df, file), read_data) %>% 
  bind_rows()
    
pro2_df = 
  pro2_df %>% 
  mutate(data = data_only)

```

##Tidy the dataframe, f manipulate file names to include the specific arm and subject ID. Also, as we are dealing with longitudinal data, we apply pivot_longer
```{r}
pro2_df_tidy = 
  pro2_df %>% 
  mutate(file = str_replace(file, "\\..*", "")) %>% 
  mutate(arm_id = file) %>% 
  separate(file, c("arm", "study_id"), sep = "_") %>% 
  unnest(data) %>% 
  pivot_longer(week_1:week_8,
               names_to = "time",
               values_to = "obs_data") 
  
```

##Plotting a spaghetti plot 
```{r}
pro2_df_tidy %>% 
  group_by(arm, study_id) %>% 
  ggplot(aes(x = time, y = obs_data, group = arm_id, color = arm)) +
  geom_line()
```

By looking at the plot, we could observe that in the experimental group, the overall trend for each individual is increasing from week1 to week8. In the control group, the participants does not seem to have a clear trend regarding the reported data from week1 to week8. The experimental group participants have higher reported data than the control group counterparts.



# Problem3
## create datasets, containing 5000 datasets, with sample size of 30, sd is 5 and population mean is 0. Then used for loop to create a list containing all the datasets. Finally, create a single dataframe containing the estimate and p_value for each of the 5000 datasets
```{r}
t_test_fxn = function(a) {
  
  t.test(a, conf.level = 0.95) %>% 
  broom::tidy() %>% 
  janitor::clean_names() %>%
  select(estimate, p_value)
  
}


output = vector("list", 5000)

for (i in 1:5000) {
  dataset = rnorm(30, mean = 0, sd = 5)
  output[[i]] = dataset
}


df_mean_0 = 
  map(output, t_test_fxn) %>% 
  bind_rows() %>% 
  mutate(a = 0) %>% 
  select(a, everything())
 
```

##For other true mean values (1, 2, 3, 4, 5, 6)
```{r}
return_est_p = function(true_mean) {
  
    map(1:5000, ~ rnorm(30, mean = true_mean, sd = 5)) %>% 
    map(., t_test_fxn) %>% 
    bind_rows()
  
}

df_one_to_six = 
  tibble(a = 1:6) %>% 
  mutate(data = map(a, return_est_p)) %>% 
  unnest(data) %>% 
  view()
```


##Join the tibble with 0 as population mean
```{r}
df_complete = 
  bind_rows(df_mean_0, df_one_to_six)
```

